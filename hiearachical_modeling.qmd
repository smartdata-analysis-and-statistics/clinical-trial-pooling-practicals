---
title: "Hierarchical Modeling"
format: html
---

# Scenario 1: Pooling Homogeneous Trials

In this example, we consider a scenario in which **all trials are homogeneous** — that is, they share similar designs, patient populations, and a consistent treatment effect.

## Simulating data

We simulate 5 trials, each with the following characteristics:

- 1:1 randomization between treatment and control arms  
- Patients drawn from the same underlying population  
- Identical baseline severity distribution across trials  
- A constant treatment effect with no variation across trials

```{r}
#| message: false
#| 
library(dplyr)
library(ggplot2)
source("R/simulate_trials.R")

# Simulate 5 trials with 100 patients each (50 per arm)
df <- simulate_trials(
  baseline_means = rep(25, 5) , # Common mean baseline
  trial_intercepts = rep(0,5), # No heterogeneity in outcome levels
  cfb_active = rep(-9.6,5),
  cfb_control = rep(-7.8,5),
  n_per_arm = 50
)
```

```{r}
#| message: false
#| echo: false
source("R/tables.R")

summarize_baseline_by_trial(df)
```

## Estimating the Pooled Treatment Effect

@fig-naive-pooling visualizes the relationship between baseline severity and change from baseline within each treatment arm using a naively pooled analysis.


```{r}
#| message: false
#| echo: false
#| fig-cap: "Observed Change from Baseline in Scenario 1"
#| label: fig-naive-pooling
#| fig-width: 10
#| fig-height: 8
source(file.path("R", "visualization.R"))
mean_labels <- df %>%
    group_by(trta) %>%
    summarise(mean_change = mean(change, na.rm = TRUE)) %>%
    mutate(label = paste0("Mean change: ", round(mean_change, 1)))
plot_change_by_treatment_with_means(df, title = "Change from Baseline by Treatment Group (Scenario 1)",
                                    subtitle = "No systematic differences across trials in baseline severity or treatment effect")
```

The plot shows that:

- The mean change in the active group is `r mean_labels %>% filter(trta == "Active") %>% pull(mean_change) %>% round(digits = 1)`
- The mean change in the control group is `r mean_labels %>% filter(trta == "Control") %>% pull(mean_change) %>% round(digits = 1)`

### Naive Analysis

We begin by estimating the pooled treatment effect using a simple regression model that adjusts for baseline severity but ignores trial structure. This reflects a naive analysis:

```{r}
#| message: false
((fit_naive <- glm(outcome ~ trta + baseline, data = df)))
```

```{r}
#| echo: false
est_naive <- coef(fit_naive)["trtaActive"]
ci_naive  <- confint.default(fit_naive)["trtaActive", ]
```

In this naive model, the estimated treatment effect is: 

`r sprintf("Treatment effect: %.2f (95%% CI: %.2f to %.2f)", est_naive, ci_naive[1], ci_naive[2])`

The figure below visualizes `fit_naive` by showing predicted outcomes across baseline severity values for each treatment group, alongside the observed data.

```{r}
#| message: false
#| echo: false
#| fig-cap: "Model-Predicted and Observed Outcomes from Naive Pooled Analysis by Treatment Group"
#| label: fig-model-fit-naive
#| fig-width: 8
#| fig-height: 6

# Prepare new data for prediction
new_data <- expand.grid(
  baseline = seq(min(df$baseline), max(df$baseline), length.out = 100),
  trta = levels(df$trta)
)

# Get model predictions
new_data$pred <- predict(fit_naive, newdata = new_data)

# Plot: Observed outcomes and model-predicted lines by treatment
ggplot() +
  # Model prediction lines (same slope, treatment-specific intercepts)
  geom_line(data = new_data, aes(x = baseline, y = pred), color = "black", linewidth  = 1.2) +

  # Observed data points
  geom_point(data = df, aes(x = baseline, y = outcome), alpha = 0.4, color = "#B90066", size = 1.5) +

  # Horizontal line at 0
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray60") +

  # Facet by treatment
  facet_wrap(~trta) +

  # Labels
  labs(
  title = "Observed Outcomes and Model-Predicted Values by Treatment Group",
  subtitle = "Regression line reflects predictions from: outcome ~ treatment + baseline",
  x = "Baseline Severity",
  y = "Observed Outcome",
  caption = paste0(
    "Treatment effect (Active vs Placebo): ", round(coef(fit_naive)["trtaActive"], 2)
  )
)+


  # Theme
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.caption = element_text(hjust = 0, size = 8, face = "italic")
  )

```

### Stratified Analysis by Trial

Next, we fit a stratified model that accounts for trial-specific intercepts by including trial as a fixed effect (without a global intercept).  This approach allows each trial to have its own baseline level of the outcome, effectively adjusting for differences in average outcomes across trials.

```{r}
#| message: false
((fit_stratified <- glm(outcome ~ -1 + trial + trta + baseline, data = df)))
```



```{r}
#| echo: false
est_stratified <- coef(fit_stratified)["trtaActive"]
ci_stratified  <- confint.default(fit_stratified)["trtaActive", ]

# Extract all coefficients related to trial intercepts
intercepts <- coef(fit_stratified)[grep("^trial", names(coef(fit_stratified)))]

# Get the minimum and maximum values
min_intercept <- min(intercepts)
max_intercept <- max(intercepts)
```

This model yields the following treatment effect estimate  (`trtaActive`), which is adjusted for trial-level differences and baseline covariates.

`r sprintf("Treatment effect: %.2f (95%% CI: %.2f to %.2f)", est_stratified, ci_stratified[1], ci_stratified[2])`

Note that all trial-specific intercepts are fairly similar (ranging from approximately `r round(min(intercepts),2)` to `r round(max(intercepts),2)`), which suggests there is no strong 'trial effect' in the data. This is consistent with how the data were simulated — the underlying outcome-generating mechanism assumed comparable average outcomes across trials, apart from random noise.

The homogeneity in trial-specific intercepts suggests that a naively pooled model with a global intercept could be reasonable in this scenario. However, this remains a strong assumption — even small differences across trials can introduce bias if not properly accounted for. Stratifying by trial offers a more robust approach by explicitly modeling these differences, even when they appear minor.

# Scenario 2: Pooling Trials with heterogeneous baseline risk

In this second scenario, we consider a setting in which trials differ in baseline severity and average outcome levels, as might occur when studies are conducted in distinct clinical environments or patient populations.

## Simulating Data

In this scenario, we simulate five clinical trials that share a **common treatment effect**. However, the trials differ systematically in terms of participant eligibility criteria and overall prognosis:

- Trial 1 enrolls patients with the lowest baseline severity (mean = 20) and has a +5 intercept shift, resulting in higher overall outcome scores.
- Trial 4 includes patients with moderately higher baseline severity (mean = 30) and includes a −10 intercept shift,  reducing overall outcome scores.
- Trial 5 involves the most severely affected patients (mean baseline = 35) and applies a −15 intercept shift, resulting in even lower outcome levels.

These shifts simulate trials enrolling progressively more severe populations, which report lower average outcomes across both treatment arms — despite having the same true treatment effect. This setup reflects a realistic source of between-trial heterogeneity.


```{r}
#| message: false

# Simulate 5 trials with 100 patients each (50 per arm)
df <- simulate_trials(
  baseline_means = c(20, 25, 25, 30, 35),     
  trial_intercepts = c(5, 0, 0, -10, -15),  
  cfb_active = rep(-9.6,5),
  cfb_control = rep(-7.8,5),
  n_per_arm = 50
)
```


```{r}
#| message: false
#| echo: false
summarize_baseline_by_trial(df)
```

## Estimating the Pooled Treatment Effect

@fig-naive-pooling-scenario2 visualizes the relationship between baseline severity and change from baseline within each treatment arm. The figure shows that:

- Patients with higher baseline severity tend to show larger improvements (greater negative change).
- The active treatment group consistently shows a greater mean improvement than the control group, across all levels of baseline severity.

Although no effect modification was simulated in this scenario, the figure illustrates how even pooled data can suggest patterns that may reflect underlying trial design or population heterogeneity.


```{r}
#| message: false
#| echo: false
#| fig-cap: "Observed Change from Baseline in Scenario 2."
#| label: fig-naive-pooling-scenario2
#| fig-width: 10
#| fig-height: 8
mean_labels <- df %>%
    group_by(trta) %>%
    summarise(mean_change = mean(change, na.rm = TRUE)) %>%
    mutate(label = paste0("Mean change: ", round(mean_change, 1)))
plot_change_by_treatment_with_means(df, 
                                    title = "Change from Baseline by Treatment Group (Scenario 2)",
                                    subtitle = "Trials differ w.r.t. baseline severity")
```


### Naive Analysis

We again begin by estimating the pooled treatment effect using a simple regression model that adjusts for baseline severity but ignores potential heterogeneity across trials — that is, it assumes all patients come from a single trial.

```{r}
#| message: false
fit_naive <- glm(outcome ~ trta + baseline, data = df)
```

```{r}
#| echo: false
est_naive <- coef(fit_naive)["trtaActive"]
se_naive <- sqrt(vcov(fit_naive)["trtaActive", "trtaActive"])
ci_naive  <- confint.default(fit_naive)["trtaActive", ]
```

In this naive model, we obtain:

`r sprintf("Treatment effect: %.2f (95%% CI: %.2f to %.2f)", est_naive, ci_naive[1], ci_naive[2])`

This result suggests a beneficial treatment effect, but it ignores systematic differences between trials — such as varying patient populations or outcome levels — which can lead to biased estimates.

The figure below visualizes `fit_naive` by showing predicted outcomes across baseline severity values for each treatment group, alongside the observed data.

```{r}
#| message: false
#| echo: false
#| fig-cap: "Model-Predicted and Observed Outcomes from Naive Pooled Analysis by Treatment Group"
#| label: fig-model-fit-naive-scenario2
#| fig-width: 8
#| fig-height: 6

# Prepare new data for prediction
new_data <- expand.grid(
  baseline = seq(min(df$baseline), max(df$baseline), length.out = 100),
  trta = levels(df$trta)
)

# Get model predictions
new_data$pred <- predict(fit_naive, newdata = new_data)

# Plot: Observed outcomes and model-predicted lines by treatment
ggplot() +
  # Model prediction lines (same slope, treatment-specific intercepts)
  geom_line(data = new_data, aes(x = baseline, y = pred), color = "black", linewidth  = 1.2) +

  # Observed data points
  geom_point(data = df, aes(x = baseline, y = outcome, color = trial), alpha = 0.4, size = 1.5) +

  # Horizontal line at 0
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray60") +

  # Facet by treatment
  facet_wrap(~trta) +

  # Labels
  labs(
  title = "Observed Outcomes and Model-Predicted Values by Treatment Group",
  subtitle = "Regression line reflects predictions from: outcome ~ treatment + baseline",
  x = "Baseline Severity",
  y = "Observed Outcome",
  caption = paste0(
    "Treatment effect (Active vs Placebo): ", round(coef(fit_naive)["trtaActive"], 2)
  )
)+


  # Theme
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.caption = element_text(hjust = 0, size = 8, face = "italic")
  )
```

Given the data observed in @fig-naive-pooling-scenario2, we may think that there is effect modification by baseline severity, with the treatment effect appearing larger in patients with higher baseline severity. We can estimate this as follows:

```{r}
#| message: false
fit_naive_hte <- glm(outcome ~ trta + baseline + trta*baseline, data = df)
```


### Stratified Analysis by Trial

To better account for between-trial differences, we now fit a stratified regression model by including trial-specific intercepts (i.e., one intercept per trial):

```{r}
#| message: false
((fit_stratified <- glm(outcome ~ -1 + trial + trta + baseline, data = df)))
```

This model allows each trial to have its own average outcome level at baseline, while still estimating a common treatment effect and adjusting for baseline severity.

```{r}
#| echo: false
est_stratified <- coef(fit_stratified)["trtaActive"]
se_stratified <- sqrt(vcov(fit_stratified)["trtaActive", "trtaActive"])
ci_stratified  <- confint.default(fit_stratified)["trtaActive", ]

# Extract all coefficients related to trial intercepts
intercepts <- coef(fit_stratified)[grep("^trial", names(coef(fit_stratified)))]

# Get the minimum and maximum values
min_intercept <- min(intercepts)
max_intercept <- max(intercepts)
```

Let’s visualize the stratified model predictions to understand how trial-specific baselines affect the outcome estimates.


```{r}
#| message: false
#| fig-cap: "Observed and model-predicted outcomes by treatment group, with trial-specific intercepts. Each line represents a trial-level regression adjusted for baseline severity."
#| label: fig-model-fit-stratified
#| fig-width: 8
#| fig-height: 6
plot_outcome_predictions_by_treatment(fit_stratified)
```

This plot illustrates how each trial follows its own fitted regression line, while the treatment effect (i.e., the difference between active and control) remains consistent across trials.

As shown in @fig-model-fit-stratified, the trial-specific intercepts range from approximately `r round(min(intercepts),2)` to `r round(max(intercepts),2)`, reflecting substantial differences in outcome levels across trials at baseline. These shifts arise from differences in the trial populations and illustrate why a naive pooled analysis (which ignores these differences) is inappropriate.

This substantial variation indicates that a naive pooling approach is no longer appropriate. Stratifying by trial ensures these baseline differences are accounted for, improving the validity of the treatment effect estimate.

The naive model estimated a treatment effect of `r sprintf("%.2f", est_naive)` (SE = `r sprintf("%.2f", se_naive)`), without accounting for trial heterogeneity. In contrast, the stratified model — which adjusts for between-trial differences — yields a more precise estimate of `r sprintf("%.2f", est_stratified)` (SE = `r sprintf("%.2f", se_stratified )`).


### Random trial effects

Instead of estimating a separate fixed intercept for each trial, we can model **trial-specific intercepts as random effects**. This approach assumes that the intercepts for each trial are not unique parameters but are instead drawn from a **common normal distribution**. In practice, this means we estimate only the mean and standard deviation of the trial intercepts — reducing the number of parameters and increasing efficiency, especially when the number of trials is large or when each trial has limited data.
```{r}
#| message: false
library(lme4)
((fit_random <- lmer(outcome ~  trta + baseline + (1|trial), data = df)))
```

```{r}
#| echo: false
est_random <-  fixef(fit_random)["trtaActive"]
se_random <- sqrt(vcov(fit_random)["trtaActive", "trtaActive"])
```

Recall the stratified model — which adjusts for between-trial differences — yielded a treatment effect of `r sprintf("%.2f", est_stratified)` (SE = `r sprintf("%.2f", se_stratified )`). The random effects model produces a similar point estimate of `r sprintf("%.2f", est_random)`, with the same standard error (SE = `r sprintf("%.2f", se_random )`). 

Although the results align in this example, the two approaches rely on different assumptions — and in other contexts, these assumptions can materially affect the estimated treatment effect.

The global fixed-effect estimates from the random-effects model are:

```{r}
fixef(fit_random)
```

These represent the overall average outcome level, treatment effect, and baseline slope across all trials.

We can extract the trial-specific intercept deviations from the global mean intercept (`r sprintf("%.2f", fixef(fit_random)["(Intercept)"] )`) as follows. 

```{r}
ranef(fit_random)
```

By design, the mean of these random effects is zero.

While the random effects approach is attractive for its parsimony and ability to borrow strength across trials, it can introduce bias in the trial-specific intercept terms (and thereby introduce bias in the pooled treatment effect). In the table below, we compare the intercepts estimated by the stratified model (fixed effects) with those from the random effects model.

```{r}
#| echo: FALSE
#| tbl-cap: "Comparison of Trial-Specific Intercepts Estimated from Stratified and Random Effects Models."
#| label: tbl-fixed-vs-random-intercepts
# Stratified (fixed effects) model
intercepts_strat <- coef(fit_stratified)[grep("^trial", names(coef(fit_stratified)))]

# Extract trial names from names
trial_names <- gsub("trial", "", names(intercepts_strat))

# Random effects model: extract BLUPs (Best Linear Unbiased Predictors)
intercepts_random <- coef(fit_random)$trial[,"(Intercept)"]

# Combine into a data.frame for plotting
intercepts_df <- data.frame(
  trial = trial_names,
  stratified = as.numeric(intercepts_strat),
  random = intercepts_random,
  stratified_txt = sprintf("%.2f", as.numeric(intercepts_strat)),
  random_txt = sprintf("%.2f", intercepts_random)
)
sd_stratified <- sd(intercepts_df$stratified)
sd_random <- sd(intercepts_df$random)


# Display: Stratified vs. Random Intercepts
intercepts_df %>% select(trial, stratified_txt, random_txt) %>%
    kable(format = "html", escape = FALSE,
          col.names = c(
            "Trial",
            "Intercept (Stratified Trial Effects)",
            "Intercept (Random Trial Effects)"
          )) %>%
    kable_styling(full_width = FALSE, position = "left", bootstrap_options = c("striped", "hover"))
```

As shown in @tbl-fixed-vs-random-intercepts, the estimated trial intercepts differ slightly between the stratified model and the random-intercepts model. The stratified model estimates a separate fixed intercept for each trial, capturing trial-specific baseline differences directly. In contrast, the random-effects model assumes that intercepts arise from a common distribution, and applies shrinkage toward the overall mean.

This shrinkage reduces variability across trials and can lead to bias in the estimated intercepts -- particularly if true trial effects differ systematically. This is reflected in the standard deviations of the trial intercepts: `r sprintf("%.2f", sd_stratified)` for the stratified model versus `r sprintf("%.2f", sd_random)` under the random-effects model, confirming a modest degree of shrinkage. Although this reduction in variability appears small, even modest shrinkage can introduce bias in the treatment effect estimate -- especially when trial-level outcome differences are correlated with treatment assignment or patient characteristics. This risk is why, in pooled analyses and multi-trial synthesis, stratifying by trial using fixed effects is often preferred. Fixed-effect models estimate each trial’s intercept independently, thus preserving true baseline differences and avoiding bias introduced by shrinkage.

# Scenario 3: Pooling Trials with heterogeneous baseline risk and treatment effect

In this third scenario, we consider a setting in which trials differ in baseline severity and average outcome levels, and where the treatment effect is modified by baseline severity.


## Simulating Data

In this scenario, we simulate five clinical trials that are identical in design and treatment effect. However, **Trials 4 and 5** differ systematically from Trials 1–3:

- Trial 1 enrolls patients with the lowest baseline severity (mean = 20) and has a +5 intercept shift, indicating higher overall outcomes.
- Trial 4 enrolls patients with moderately higher baseline severity (mean = 30) and includes a −10 intercept shift, lowering overall outcomes.
- Trial 5 enrolls patients with the highest baseline severity (mean = 35) and includes a stronger −15 intercept shift to further reduce outcome levels.

These shifts simulate trials that include more severely affected populations and report lower outcome scores across both treatment arms, despite having the same true treatment effect. This setup reflects a realistic source of between-trial heterogeneity.

```{r}
#| message: false

df <- simulate_trials(
  baseline_means = c(20, 25, 25, 30, 35),     
  trial_intercepts = c(5, 0, 0, -10, -15),
  cfb_active = rep(-9.6,5),
  cfb_control = rep(-7.8,5),
  n_per_arm = 50,
  beta_W = c(0, -0.05, -0.1, -0.15, -0.2),  
  beta_A = 0.1
)
```


```{r}
#| message: false
#| echo: false
summarize_baseline_by_trial(df)
```

## Estimating the Pooled Treatment Effect

@fig-naive-pooling-scenario3 visualizes the relationship between baseline severity and change from baseline within each treatment arm. The figure shows that:

- Patients with higher baseline severity tend to show larger improvements (greater negative change).
- The active treatment group shows a greater mean improvement than the control group.


```{r}
#| message: false
#| echo: false
#| fig-cap: "Observed Change from Baseline in Scenario 3."
#| label: fig-naive-pooling-scenario3
#| fig-width: 10
#| fig-height: 8
mean_labels <- df %>%
    group_by(trta) %>%
    summarise(mean_change = mean(change, na.rm = TRUE)) %>%
    mutate(label = paste0("Mean change: ", round(mean_change, 1)))
plot_change_by_treatment_with_means(df, title = "Change from Baseline by Treatment Group (Scenario 3)")
```

### Random treatment effects

We investigate between-trial heterogeneity in treatment effects using a linear mixed model with random slopes for treatment and fixed intercepts by trial:

```{r}
#| message: false
((fit_random_hte <- lmer(outcome ~ -1 + trial + baseline:trial + trt + (0 + trt | trial), data = df)))
```


In this formula:

- `-1 + trial`: Fixed intercept per trial
- `baseline + trt`: Fixed effect of baseline and treatment
- `(0 + trt | trial)`: Random treatment effect per trial

The fitted effects are visualized in @fig-model-fit-stratified-scenario3. We can derive an approximate 95\% confidence interval as follows:

```{r}
((ci_mu <- confint(fit_random_hte, method = "Wald")["trt", ]))
``` 

To derive an approximate 95% prediction interval for the treatment effect, we can use the following approach:

```{r}
# Extract mean treatment effect
mu <- fixef(fit_random_hte)["trt"]
tau2 <- as.numeric(VarCorr(fit_random_hte)$trial["trt", "trt"])
var_mu <- vcov(fit_random_hte)["trt", "trt"]

# Number of studies
n_studies <- length(unique(df$trial))
df_t <- n_studies - 2

# t critical value for 95% PI
t_crit <- qt(0.975, df = df_t)

# 95% Prediction Interval
pred_lower <- mu - t_crit * sqrt(tau2 + var_mu)
pred_upper <- mu + t_crit * sqrt(tau2 + var_mu)

cbind(pred_lower, pred_upper)
```


```{r}
#| echo: false
#| fig-cap: "Trial-Specific Estimates from the Random-Effects Model. Estimated intercepts terms (left) and treatment effects (right) for each trial are shown, based on a linear mixed-effects model with fixed intercepts by trial and random slopes for treatment. The black points and lines represent point estimates and 95% confidence intervals. The pooled treatment effect estimate is shown at the bottom, with dashed red lines indicating the 95% prediction interval for a new trial."
#| label: fig-model-fit-stratified-scenario3
#| fig-width: 8
#| fig-height: 6
coefs <- coef(fit_random_hte)$trial


# Assume `coefs` is the result of coef(fit_random_hte)$trial
coefs_df <- coefs %>%
  tibble::rownames_to_column("trial")

ci_fixed <- confint(fit_random_hte, level = 0.95, method = "Wald") %>%
  as.data.frame() %>%
  tibble::rownames_to_column("term") %>%
  filter(grepl("^trialTrial_", term)) %>%
  mutate(trial = gsub("trialTrial_", "Trial_", term)) %>%
  rename(ci_lower = `2.5 %`, ci_upper = `97.5 %`) %>%
  select(trial, ci_lower, ci_upper)

# Extract intercepts (same for all rows → just take the first row)
intercepts <- coefs_df[1, paste0("trialTrial_", 1:5)] %>%
  pivot_longer(everything(), names_to = "trial_label", values_to = "estimate") %>%
  mutate(
    trial = gsub("trialTrial_", "Trial_", trial_label),
    parameter = "intercept"
  ) %>%
  left_join(ci_fixed, by = "trial") %>%
  select(trial, parameter, estimate, ci_lower, ci_upper)

# Extract trial-specific treatment effects
slopes <- coefs_df %>%
  select(trial, trt) %>%
  mutate(parameter = "treatment", estimate = trt) %>%
  select(trial, parameter, estimate)

# Combine for plotting
plot_df <- bind_rows(intercepts, slopes)

# Add summary
plot_df <- plot_df %>% add_row(data.frame(trial="Pooled", parameter="treatment", 
                                          estimate=mu, 
                                          ci_lower=ci_mu[1], ci_upper=ci_mu[2]))

# Plot forest with facets
ggplot(plot_df, aes(x = estimate, y = trial)) +
  geom_point() +
  
   # Prediction interval for "Pooled" only
  geom_errorbarh(
    data = data.frame(
      trial = "Pooled",
      parameter = "treatment",
      estimate = mu,
      pred_lower = pred_lower,
      pred_upper = pred_upper
    ),
    aes(xmin = pred_lower, xmax = pred_upper),
    height = 0.4,
    color = "darkred",
    linetype = "dashed"
  ) +
  
  geom_errorbarh(aes(xmin = ci_lower, xmax = ci_upper), height = 0.2, na.rm = TRUE) +
  
  facet_wrap(~parameter, scales = "free_x") +
  labs(
    title = "Trial-specific Estimates from Random-Effects Model",
    subtitle = "Dashed lines indicate 95% Prediction Interval for Pooled Treatment Effect",
    x = "Estimate",
    y = NULL
  ) +
  theme_minimal()

```




Let’s visualize the stratified model predictions to understand how trial-specific baselines affect the outcome estimates.



## Investigating effect modification
