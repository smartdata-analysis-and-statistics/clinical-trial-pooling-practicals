---
title: "Hierarchical Modeling"
author: "Thomas Debray"
date: today
format: 
  html:
    number-sections: true
    toc: true
    toc-depth: 2
---

# Scenario 1: Pooling Homogeneous Trials

In this example, we consider a scenario in which **all trials are homogeneous** — that is, they share similar designs, patient populations, and a consistent treatment effect.

## Simulating data

We simulate 5 trials, each with the following characteristics:

- 1:1 randomization between treatment and control arms  
- Patients drawn from the same underlying population  
- Identical baseline severity distribution across trials  
- A constant treatment effect with no variation across trials

```{r}
#| message: false
#| 
library(dplyr)
library(ggplot2)
source("R/simulate_trials.R")

# Simulate 5 trials with 100 patients each (50 per arm)
df <- simulate_trials(
  baseline_means = rep(25, 5) , # Common mean baseline
  trial_intercepts = rep(0,5), # No heterogeneity in outcome levels
  cfb_active = rep(-9.6,5),
  cfb_control = rep(-7.8,5),
  n_per_arm = 50
)
```

```{r}
#| message: false
#| echo: false
source("R/tables.R")

summarize_baseline_by_trial(df)
```

## Estimating the Pooled Treatment Effect

@fig-naive-pooling visualizes the relationship between baseline severity and change from baseline within each treatment arm using a naively pooled analysis.


```{r}
#| message: false
#| echo: false
#| fig-cap: "Observed Change from Baseline in Scenario 1"
#| label: fig-naive-pooling
#| fig-width: 10
#| fig-height: 8
source(file.path("R", "visualization.R"))
mean_labels <- df %>%
    group_by(trta) %>%
    summarise(mean_change = mean(change, na.rm = TRUE)) %>%
    mutate(label = paste0("Mean change: ", round(mean_change, 1)))
plot_change_by_treatment_with_means(df, title = "Change from Baseline by Treatment Group (Scenario 1)",
                                    subtitle = "No systematic differences across trials in baseline severity or treatment effect")
```

The plot shows that:

- The mean change in the active group is `r mean_labels %>% filter(trta == "Active") %>% pull(mean_change) %>% round(digits = 1)`
- The mean change in the control group is `r mean_labels %>% filter(trta == "Control") %>% pull(mean_change) %>% round(digits = 1)`

### Naive Analysis

We begin by estimating the pooled treatment effect using a simple regression model that adjusts for baseline severity but ignores trial structure. This reflects a naive analysis:

```{r}
#| message: false
((fit_naive <- glm(outcome ~ trta + baseline, data = df)))
```

```{r}
#| echo: false
est_naive <- coef(fit_naive)["trtaActive"]
ci_naive  <- confint.default(fit_naive)["trtaActive", ]
```

In this naive model, the estimated treatment effect is: 

`r sprintf("Treatment effect: %.2f (95%% CI: %.2f to %.2f)", est_naive, ci_naive[1], ci_naive[2])`

The figure below visualizes `fit_naive` by showing predicted outcomes across baseline severity values for each treatment group, alongside the observed data.

```{r}
#| message: false
#| echo: false
#| fig-cap: "Model-Predicted and Observed Outcomes from Naive Pooled Analysis by Treatment Group"
#| label: fig-model-fit-naive
#| fig-width: 8
#| fig-height: 6

# Prepare new data for prediction
new_data <- expand.grid(
  baseline = seq(min(df$baseline), max(df$baseline), length.out = 100),
  trta = levels(df$trta)
)

# Get model predictions
new_data$pred <- predict(fit_naive, newdata = new_data)

# Plot: Observed outcomes and model-predicted lines by treatment
ggplot() +
  # Model prediction lines (same slope, treatment-specific intercepts)
  geom_line(data = new_data, aes(x = baseline, y = pred), color = "black", linewidth  = 1.2) +

  # Observed data points
  geom_point(data = df, aes(x = baseline, y = outcome), alpha = 0.4, color = "#B90066", size = 1.5) +

  # Horizontal line at 0
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray60") +

  # Facet by treatment
  facet_wrap(~trta) +

  # Labels
  labs(
  title = "Observed Outcomes and Model-Predicted Values by Treatment Group",
  subtitle = "Regression line reflects predictions from: outcome ~ treatment + baseline",
  x = "Baseline Severity",
  y = "Observed Outcome",
  caption = paste0(
    "Treatment effect (Active vs Placebo): ", round(coef(fit_naive)["trtaActive"], 2)
  )
)+


  # Theme
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.caption = element_text(hjust = 0, size = 8, face = "italic")
  )

```

### Stratified Analysis by Trial

Next, we fit a stratified model that accounts for trial-specific intercepts by including trial as a fixed effect (without a global intercept).  This approach allows each trial to have its own baseline level of the outcome, effectively adjusting for differences in average outcomes across trials.

```{r}
#| message: false
((fit_stratified <- glm(outcome ~ -1 + trial + trta + baseline, data = df)))
```



```{r}
#| echo: false
est_stratified <- coef(fit_stratified)["trtaActive"]
ci_stratified  <- confint.default(fit_stratified)["trtaActive", ]

# Extract all coefficients related to trial intercepts
intercepts <- coef(fit_stratified)[grep("^trial", names(coef(fit_stratified)))]

# Get the minimum and maximum values
min_intercept <- min(intercepts)
max_intercept <- max(intercepts)
```

This model yields the following treatment effect estimate  (`trtaActive`), which is adjusted for trial-level differences and baseline covariates.

`r sprintf("Treatment effect: %.2f (95%% CI: %.2f to %.2f)", est_stratified, ci_stratified[1], ci_stratified[2])`

Note that all trial-specific intercepts are fairly similar (ranging from approximately `r round(min(intercepts),2)` to `r round(max(intercepts),2)`), which suggests there is no strong 'trial effect' in the data. This is consistent with how the data were simulated — the underlying outcome-generating mechanism assumed comparable average outcomes across trials, apart from random noise.

The homogeneity in trial-specific intercepts suggests that a naively pooled model with a global intercept could be reasonable in this scenario. However, this remains a strong assumption — even small differences across trials can introduce bias if not properly accounted for. Stratifying by trial offers a more robust approach by explicitly modeling these differences, even when they appear minor.

# Scenario 2: Pooling Trials with heterogeneous baseline risk

In this second scenario, we consider a setting in which trials differ in baseline severity and average outcome levels, as might occur when studies are conducted in distinct clinical environments or patient populations.

## Simulating Data

In this scenario, we simulate five clinical trials that share a **common treatment effect**. However, the trials differ systematically in terms of participant eligibility criteria and overall prognosis:

- Trial 1 enrolls patients with the lowest baseline severity (mean = 20) and has a +5 intercept shift, resulting in higher overall outcome scores.
- Trial 4 includes patients with moderately higher baseline severity (mean = 30) and includes a −10 intercept shift,  reducing overall outcome scores.
- Trial 5 involves the most severely affected patients (mean baseline = 35) and applies a −15 intercept shift, resulting in even lower outcome levels.

These shifts simulate trials enrolling progressively more severe populations, which report lower average outcomes across both treatment arms — despite having the same true treatment effect. This setup reflects a realistic source of between-trial heterogeneity.


```{r}
#| message: false

# Simulate 5 trials with 100 patients each (50 per arm)
df <- simulate_trials(
  baseline_means = c(20, 25, 25, 30, 35),     
  trial_intercepts = c(5, 0, 0, -10, -15),  
  cfb_active = rep(-9.6,5),
  cfb_control = rep(-7.8,5),
  n_per_arm = 50
)
```


```{r}
#| message: false
#| echo: false
summarize_baseline_by_trial(df)
```

## Estimating the Pooled Treatment Effect

@fig-naive-pooling-scenario2 visualizes the relationship between baseline severity and change from baseline within each treatment arm. The figure shows that:

- Patients with higher baseline severity tend to show larger improvements (greater negative change).
- The active treatment group consistently shows a greater mean improvement than the control group, across all levels of baseline severity.

Although no effect modification was simulated in this scenario, the figure illustrates how even pooled data can suggest patterns that may reflect underlying trial design or population heterogeneity.


```{r}
#| message: false
#| echo: false
#| fig-cap: "Observed Change from Baseline in Scenario 2."
#| label: fig-naive-pooling-scenario2
#| fig-width: 10
#| fig-height: 8
mean_labels <- df %>%
    group_by(trta) %>%
    summarise(mean_change = mean(change, na.rm = TRUE)) %>%
    mutate(label = paste0("Mean change: ", round(mean_change, 1)))
plot_change_by_treatment_with_means(df, 
                                    title = "Change from Baseline by Treatment Group (Scenario 2)",
                                    subtitle = "Trials differ w.r.t. baseline severity")
```


### Naive Analysis

We again begin by estimating the pooled treatment effect using a simple regression model that adjusts for baseline severity but ignores potential heterogeneity across trials — that is, it assumes all patients come from a single trial.

```{r}
#| message: false
fit_naive <- glm(outcome ~ trta + baseline, data = df)
```

```{r}
#| echo: false
est_naive <- coef(fit_naive)["trtaActive"]
se_naive <- sqrt(vcov(fit_naive)["trtaActive", "trtaActive"])
ci_naive  <- confint.default(fit_naive)["trtaActive", ]
```

In this naive model, we obtain:

`r sprintf("Treatment effect: %.2f (95%% CI: %.2f to %.2f)", est_naive, ci_naive[1], ci_naive[2])`

This result suggests a beneficial treatment effect, but it ignores systematic differences between trials — such as varying patient populations or outcome levels — which can lead to biased estimates.

The figure below visualizes `fit_naive` by showing predicted outcomes across baseline severity values for each treatment group, alongside the observed data.

```{r}
#| message: false
#| echo: false
#| fig-cap: "Model-Predicted and Observed Outcomes from Naive Pooled Analysis by Treatment Group"
#| label: fig-model-fit-naive-scenario2
#| fig-width: 8
#| fig-height: 6

# Prepare new data for prediction
new_data <- expand.grid(
  baseline = seq(min(df$baseline), max(df$baseline), length.out = 100),
  trta = levels(df$trta)
)

# Get model predictions
new_data$pred <- predict(fit_naive, newdata = new_data)

# Plot: Observed outcomes and model-predicted lines by treatment
ggplot() +
  # Model prediction lines (same slope, treatment-specific intercepts)
  geom_line(data = new_data, aes(x = baseline, y = pred), color = "black", linewidth  = 1.2) +

  # Observed data points
  geom_point(data = df, aes(x = baseline, y = outcome, color = trial), alpha = 0.4, size = 1.5) +

  # Horizontal line at 0
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray60") +

  # Facet by treatment
  facet_wrap(~trta) +

  # Labels
  labs(
  title = "Observed Outcomes and Model-Predicted Values by Treatment Group",
  subtitle = "Regression line reflects predictions from: outcome ~ treatment + baseline",
  x = "Baseline Severity",
  y = "Observed Outcome",
  caption = paste0(
    "Treatment effect (Active vs Placebo): ", round(coef(fit_naive)["trtaActive"], 2)
  )
)+


  # Theme
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.caption = element_text(hjust = 0, size = 8, face = "italic")
  )
```

Given the data observed in @fig-naive-pooling-scenario2, we may think that there is effect modification by baseline severity, with the treatment effect appearing larger in patients with higher baseline severity. We can estimate this as follows:

```{r}
#| message: false
fit_naive_hte <- glm(outcome ~ trta + baseline + trta*baseline, data = df)
```


### Stratified Analysis by Trial

To better account for between-trial differences, we now fit a stratified regression model by including trial-specific intercepts (i.e., one intercept per trial):

```{r}
#| message: false
((fit_stratified <- glm(outcome ~ -1 + trial + trta + baseline, data = df)))
```

This model allows each trial to have its own average outcome level at baseline, while still estimating a common treatment effect and adjusting for baseline severity.

```{r}
#| echo: false
est_stratified <- coef(fit_stratified)["trtaActive"]
se_stratified <- sqrt(vcov(fit_stratified)["trtaActive", "trtaActive"])
ci_stratified  <- confint.default(fit_stratified)["trtaActive", ]

# Extract all coefficients related to trial intercepts
intercepts <- coef(fit_stratified)[grep("^trial", names(coef(fit_stratified)))]

# Get the minimum and maximum values
min_intercept <- min(intercepts)
max_intercept <- max(intercepts)
```

Let’s visualize the stratified model predictions to understand how trial-specific baselines affect the outcome estimates.


```{r}
#| message: false
#| fig-cap: "Observed and model-predicted outcomes by treatment group, with trial-specific intercepts. Each line represents a trial-level regression adjusted for baseline severity."
#| label: fig-model-fit-stratified
#| fig-width: 8
#| fig-height: 6
plot_outcome_predictions_by_treatment(fit_stratified)
```

This plot illustrates how each trial follows its own fitted regression line, while the treatment effect (i.e., the difference between active and control) remains consistent across trials.

As shown in @fig-model-fit-stratified, the trial-specific intercepts range from approximately `r round(min(intercepts),2)` to `r round(max(intercepts),2)`, reflecting substantial differences in outcome levels across trials at baseline. These shifts arise from differences in the trial populations and illustrate why a naive pooled analysis (which ignores these differences) is inappropriate.

This substantial variation indicates that a naive pooling approach is no longer appropriate. Stratifying by trial ensures these baseline differences are accounted for, improving the validity of the treatment effect estimate.

The naive model estimated a treatment effect of `r sprintf("%.2f", est_naive)` (SE = `r sprintf("%.2f", se_naive)`), without accounting for trial heterogeneity. In contrast, the stratified model — which adjusts for between-trial differences — yields a more precise estimate of `r sprintf("%.2f", est_stratified)` (SE = `r sprintf("%.2f", se_stratified )`).


### Random trial effects

Instead of estimating a separate fixed intercept for each trial, we can model **trial-specific intercepts as random effects**. This approach assumes that the intercepts for each trial are not unique parameters but are instead drawn from a **common normal distribution**. In practice, this means we estimate only the mean and standard deviation of the trial intercepts — reducing the number of parameters and increasing efficiency, especially when the number of trials is large or when each trial has limited data.
```{r}
#| message: false
library(lme4)
((fit_random <- lmer(outcome ~  trta + baseline + (1|trial), data = df)))
```

```{r}
#| echo: false
est_random <-  fixef(fit_random)["trtaActive"]
se_random <- sqrt(vcov(fit_random)["trtaActive", "trtaActive"])
```

Recall the stratified model — which adjusts for between-trial differences — yielded a treatment effect of `r sprintf("%.2f", est_stratified)` (SE = `r sprintf("%.2f", se_stratified )`). The random effects model produces a similar point estimate of `r sprintf("%.2f", est_random)`, with the same standard error (SE = `r sprintf("%.2f", se_random )`). 

Although the results align in this example, the two approaches rely on different assumptions — and in other contexts, these assumptions can materially affect the estimated treatment effect.

The global fixed-effect estimates from the random-effects model are:

```{r}
fixef(fit_random)
```

These represent the overall average outcome level, treatment effect, and baseline slope across all trials.

We can extract the trial-specific intercept deviations from the global mean intercept (`r sprintf("%.2f", fixef(fit_random)["(Intercept)"] )`) as follows. 

```{r}
ranef(fit_random)
```

By design, the mean of these random effects is zero.

While the random effects approach is attractive for its parsimony and ability to borrow strength across trials, it can introduce bias in the trial-specific intercept terms (and thereby introduce bias in the pooled treatment effect). In the table below, we compare the intercepts estimated by the stratified model (fixed effects) with those from the random effects model.

```{r}
#| echo: FALSE
#| tbl-cap: "Comparison of Trial-Specific Intercepts Estimated from Stratified and Random Effects Models."
#| label: tbl-fixed-vs-random-intercepts
# Stratified (fixed effects) model
intercepts_strat <- coef(fit_stratified)[grep("^trial", names(coef(fit_stratified)))]

# Extract trial names from names
trial_names <- gsub("trial", "", names(intercepts_strat))

# Random effects model: extract BLUPs (Best Linear Unbiased Predictors)
intercepts_random <- coef(fit_random)$trial[,"(Intercept)"]

# Combine into a data.frame for plotting
intercepts_df <- data.frame(
  trial = trial_names,
  stratified = as.numeric(intercepts_strat),
  random = intercepts_random,
  stratified_txt = sprintf("%.2f", as.numeric(intercepts_strat)),
  random_txt = sprintf("%.2f", intercepts_random)
)
sd_stratified <- sd(intercepts_df$stratified)
sd_random <- sd(intercepts_df$random)


# Display: Stratified vs. Random Intercepts
intercepts_df %>% select(trial, stratified_txt, random_txt) %>%
    kable(format = "html", escape = FALSE,
          col.names = c(
            "Trial",
            "Intercept (Stratified Trial Effects)",
            "Intercept (Random Trial Effects)"
          )) %>%
    kable_styling(full_width = FALSE, position = "left", bootstrap_options = c("striped", "hover"))
```

As shown in @tbl-fixed-vs-random-intercepts, the estimated trial intercepts differ slightly between the stratified model and the random-intercepts model. The stratified model estimates a separate fixed intercept for each trial, capturing trial-specific baseline differences directly. In contrast, the random-effects model assumes that intercepts arise from a common distribution, and applies shrinkage toward the overall mean.

This shrinkage reduces variability across trials and can lead to bias in the estimated intercepts -- particularly if true trial effects differ systematically. This is reflected in the standard deviations of the trial intercepts: `r sprintf("%.2f", sd_stratified)` for the stratified model versus `r sprintf("%.2f", sd_random)` under the random-effects model, confirming a modest degree of shrinkage. Although this reduction in variability appears small, even modest shrinkage can introduce bias in the treatment effect estimate -- especially when trial-level outcome differences are correlated with treatment assignment or patient characteristics. This risk is why, in pooled analyses and multi-trial synthesis, stratifying by trial using fixed effects is often preferred. Fixed-effect models estimate each trial’s intercept independently, thus preserving true baseline differences and avoiding bias introduced by shrinkage.

# Scenario 3: Pooling Trials with heterogeneous baseline risk and treatment effect

In this third scenario, we consider a setting in which trials differ in baseline severity and average outcome levels, and where the treatment effect is modified by baseline severity.


## Simulating Data

In this scenario, we simulate five clinical trials that are identical in design and treatment effect. However, **Trials 4 and 5** differ systematically from Trials 1–3:

- Trial 1 enrolls patients with the lowest baseline severity (mean = 20) and has a +5 intercept shift, indicating higher overall outcomes.
- Trial 4 enrolls patients with moderately higher baseline severity (mean = 30) and includes a −10 intercept shift, lowering overall outcomes.
- Trial 5 enrolls patients with the highest baseline severity (mean = 35) and includes a stronger −15 intercept shift to further reduce outcome levels.

These shifts simulate trials that include more severely affected populations and report lower outcome scores across both treatment arms, despite having the same true treatment effect. This setup reflects a realistic source of between-trial heterogeneity.

```{r}
#| message: false
df <- simulate_trials(
  baseline_means = c(20, 25, 25, 30, 35),     
  trial_intercepts = c(5, 0, 0, -10, -15),
  cfb_active = rep(-9.6,5),
  cfb_control = rep(-7.8,5),
  n_per_arm = 50,
  beta_W = rep(-0.15,5),  
  beta_A = 0.35,
  seed = 2025
)
```


```{r}
#| message: false
#| echo: false
summarize_baseline_by_trial(df)
```

## Estimating the Pooled Treatment Effect

@fig-naive-pooling-scenario3 visualizes the relationship between baseline severity and change from baseline within each treatment arm. The figure shows that:

- Patients with higher baseline severity tend to show larger improvements (greater negative change).
- The active treatment group shows a greater mean improvement than the control group.


```{r}
#| message: false
#| echo: false
#| fig-cap: "Observed Change from Baseline in Scenario 3."
#| label: fig-naive-pooling-scenario3
#| fig-width: 10
#| fig-height: 8
mean_labels <- df %>%
    group_by(trta) %>%
    summarise(mean_change = mean(change, na.rm = TRUE)) %>%
    mutate(label = paste0("Mean change: ", round(mean_change, 1)))
plot_change_by_treatment_with_means(df, title = "Change from Baseline by Treatment Group (Scenario 3)")
```

## Assessing Between-Trial Heterogeneity in Treatment Effects {#sec-stratifiedREmodel}

We investigate between-trial heterogeneity in treatment effects using a linear mixed model with random slopes for treatment and fixed intercepts by trial:

```{r}
#| message: false
fit_random_hte <- lmer(outcome ~ -1 + trial + baseline:trial + 
                         trt + (0 + trt | trial), data = df)
```

In this formula:

- `-1 + trial`: Includes a fixed intercept for each trial
- `baseline:trial`: Allows each trial to have its own slope for baseline (trial-specific baseline effect)
- `trt`: Estimates the average treatment effect across trials
- `(0 + trt | trial)`: Allows the treatment effect to vary randomly by trial

**Note**: The `trt` variable is modeled as a numeric binary indicator (0 = control, 1 = active treatment), rather than as a categorical factor. This allows us to directly interpret the fixed effect of `trt` as the **average treatment effect**. Additionally, modeling `trt` as numeric is necessary to estimate a random slope for `trt` per trial via `(0 + trt | trial)`. This would not be valid if `trt` were treated as a factor (e.g., using `trta`).

The results are as follows:
```{r}
#| echo: false
fit_random_hte 
```

We compute the 95\% confidence interval for the average treatment effect and a prediction interval that reflects heterogeneity across trials. The prediction interval estimates the range where a future trial's treatment effect might fall.

```{r}
((ci_mu <- confint(fit_random_hte, method = "Wald")["trt", ]))
``` 

To derive an approximate 95% prediction interval for the treatment effect, we can use the following approach:

```{r}
# Extract mean treatment effect
mu <- fixef(fit_random_hte)["trt"]
tau2 <- VarCorr(fit_random_hte)$trial["trt", "trt"]
var_mu <- vcov(fit_random_hte)["trt", "trt"]

# Number of studies
n_studies <- length(unique(df$trial))
df_t <- n_studies - 2

# t critical value for 95% PI
t_crit <- qt(0.975, df = df_t)

# 95% Prediction Interval
pred_lower <- mu - t_crit * sqrt(tau2 + var_mu)
pred_upper <- mu + t_crit * sqrt(tau2 + var_mu)

cbind(pred_lower, pred_upper)
```

The prediction interval is wide, suggesting meaningful heterogeneity in treatment effects across trials. This implies that in some future settings, the treatment could be less effective compared to the pooled estimate.

The fitted effects and prediction interval are visualized in @fig-model-fit-stratified-scenario3.

```{r}
#| echo: false
#| fig-cap: "Trial-Specific Estimates from the Random-Effects Model. Estimated intercepts terms (left) and treatment effects (right) for each trial are shown, based on a linear mixed-effects model with fixed intercepts by trial and random slopes for treatment. The black points and lines represent point estimates and 95% confidence intervals. The pooled treatment effect estimate is shown at the bottom, with dashed red lines indicating the 95% prediction interval for a new trial."
#| label: fig-model-fit-stratified-scenario3
#| fig-width: 8
#| fig-height: 6
plot_mixed_model_effects(fit_random_hte)
```

## Investigating effect modification

We now explore whether the observed treatment effect heterogeneity can be explained by effect modification, using interaction terms between treatment and baseline severity.

### Common interaction effect {#sec-commonInteraction}

A simple extension of our linear mixed model defined in @sec-stratifiedREmodel -- with fixed intercepts per trial and random slopes for treatment -- is to include a **common treatment-by-baseline interaction** term. This allows us to assess whether baseline severity modifies the treatment effect, assuming the interaction is constant across trials.

```{r}
#| message: false
fit_hte_1 <- lmer(outcome ~ -1 + trial + baseline:trial + trt + 
                    baseline:trt + (0 + trt | trial) , data = df)
```

In this formula:

- `-1 + trial`: Fixed intercept per trial
- `baseline:trial`: Fixed effect for baseline severity per trial
- `trt`: Estimates the average treatment effect across trials
- `baseline:trt`: Interaction between baseline severity and treatment
- `(0 + trt | trial)`: Allows the treatment effect to vary randomly by trial

The results are as follows:
```{r}
#| echo: false
# Extract SD of random slope for trt within trial
tau_fit_hte_1 <- as.data.frame(VarCorr(fit_hte_1)) %>%
  dplyr::filter(grp == "trial", var1 == "trt", is.na(var2)) %>%
  dplyr::pull(sdcor)

fit_hte_1 
```

The coefficients `trt` and `baseline:trt` define a linear relationship between baseline severity and the estimated treatment effect (Active vs Control). In @fig-hte-commoninteraction, we visualize this relationship using the model's fixed effects, with a dashed line indicating no treatment effect.


```{r}
#| echo: false
#| message: false
#| fig-cap: "Estimated treatment effect (active vs control) as a function of baseline severity. The red dashed line at 0 indicates no treatment benefit. Negative values suggest a favorable effect of the active treatment, while positive values suggest harm. The distribution of baseline values across the included trials is shown as rug marks along the x-axis. Colored dots represent the expected (marginal) treatment effect within each trial, calculated by averaging predicted outcomes across that trial's observed baseline distribution."
#| label: fig-hte-commoninteraction
#| fig-width: 8
#| fig-height: 5

library(emmeans)

baseline_means <- df %>%
  group_by(trial) %>%
  summarise(mean_baseline = mean(baseline), .groups = "drop")


# Create a grid of all observed combinations of baseline, trial, and trt
grid_df <- df %>%
  dplyr::select(trial, baseline) %>%
  tidyr::expand_grid(trt = c(0, 1))

# Predict outcome under each treatment
grid_df$pred <- predict(fit_hte_1, newdata = grid_df, re.form = NA)  # marginalize over random effects

# Calculate average predicted outcome per trial and trt
avg_outcome <- grid_df %>%
  group_by(trial, trt) %>%
  summarise(mean_pred = mean(pred), .groups = "drop") %>%
  tidyr::pivot_wider(names_from = trt, values_from = mean_pred, names_prefix = "trt_") %>%
  mutate(treatment_effect = trt_1 - trt_0)

avg_outcome_annotated <- avg_outcome %>%
  left_join(baseline_means, by = "trial")

# Extract fixed effects
beta_trt <- fixef(fit_hte_1)["trt"]
beta_trt_baseline <- fixef(fit_hte_1)["baseline:trt"]

# Create baseline range
baseline_vals <- seq(min(df$baseline), max(df$baseline), length.out = 100)

# Calculate marginal treatment effect at each baseline value
treatment_effect <- beta_trt + beta_trt_baseline * baseline_vals

# Create data frame for plotting
te_df <- data.frame(
  baseline = baseline_vals,
  treatment_effect = treatment_effect
)

# Plot the treatment effect function
ggplot(te_df, aes(x = baseline, y = treatment_effect)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  geom_line(linewidth = 1.2) +
  coord_cartesian(xlim = range(df$baseline)) +
  geom_rug(data = df, aes(x = baseline), inherit.aes = FALSE, sides = "b", alpha = 0.3) +
  # Add per-trial average treatment effects
  geom_point(data = avg_outcome_annotated,
             aes(x = mean_baseline, y = treatment_effect, color = trial),
             size = 3,
             alpha = 0.9) +
  labs(
    x = "Baseline Severity",
    y = "Treatment Effect (Active vs Control)"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    legend.title = element_blank()
  )
```

Although the model includes a treatment-by-baseline interaction (`baseline:trt`), there remains evidence of heterogeneity in treatment effect across trials. This is indicated by the random slope variance for treatment (`trt | trial`), with an estimated standard deviation of `r sprintf("%.2f", tau_fit_hte_1)`. 

### Random within-study interaction effects

In this approach, we stratify all parameters **except** for the treatment-by-covariate interaction term by trial. This includes the parameter representing the treatment effect at the covariate's reference value. All "nuisance" parameters (i.e., parameters not of primary interest) are allowed to vary across trials. A random effect is included only on the within-trial interaction term (`baseline:trt`), capturing heterogeneity in effect modification across trials.

```{r}
#| message: FALSE
#| warning: FALSE
fit_hte_2 <- lmer(outcome ~ -1 + trial + baseline:trial + trt:trial + 
                    baseline:trt + (0 + baseline:trt | trial) , data = df)
```

This stratification of all nuisance parameters -- including the treatment effect at the covariate's reference value — ensures that the estimate of `baseline:trt` (the treatment–covariate interaction) is informed purely by within-trial comparisons.

The fitted model is:
```{r}
#| echo: false
fit_hte_2 
```

Since the between-trial variance in the interaction effects is close to zero, we may simplify the model by removing the random component and estimating a common interaction term across trials:

```{r}
#| message: FALSE
#| warning: FALSE
fit_hte_2b <- glm(outcome ~ -1 + trial + baseline:trial + trt:trial + 
                    baseline:trt, data = df)
```

The coefficients `trt:trial` and `baseline:trt` define a linear relationship between baseline severity and the estimated treatment effect (active vs control), with a trial-specific intercept and a common interaction slope. In @fig-hte-rwi, we visualize this relationship using both model-predicted curves and trial-level marginal estimates.

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Estimated treatment effect (active vs control) as a function of baseline severity for each trial. The red dashed line at 0 indicates no treatment benefit. Negative values suggest a favorable effect of the active treatment, while positive values suggest harm. Rug marks show the distribution of baseline values. Coloured lines and dots represent, respectively, the model-based treatment-effect curves and the marginal (average) treatment effect within each trial."
#| label: fig-hte-rwi
#| fig-width: 8
#| fig-height: 5


# ----- 1. Trial-level intercepts and common slope -----------------------------
trials          <- unique(df$trial)

# Use coef() for glm model
beta_slope <- coef(fit_hte_2b)["baseline:trt"]
beta_intercepts <- sapply(trials, function(t) coef(fit_hte_2b)[paste0("trial", t, ":trt")])

# Create treatment effect curves
baseline_vals <- seq(min(df$baseline), max(df$baseline), length.out = 100)
te_df <- expand.grid(baseline = baseline_vals, trial = trials) %>%
  mutate(treatment_effect = beta_intercepts[trial] + beta_slope * baseline)

# Compute marginal treatment effect per trial
grid_df <- df %>%
  select(trial, baseline) %>%
  expand_grid(trt = c(0, 1))

grid_df$pred <- predict(fit_hte_2b, newdata = grid_df)

avg_outcome <- grid_df %>%
  group_by(trial, trt) %>%
  summarise(mean_pred = mean(pred), .groups = "drop") %>%
  pivot_wider(names_from = trt, values_from = mean_pred, names_prefix = "trt_") %>%
  mutate(treatment_effect = trt_1 - trt_0)

# Compute mean baseline per trial
baseline_means <- df %>%
  group_by(trial) %>%
  summarise(mean_baseline = mean(baseline), .groups = "drop")

# Annotate trial-level outcomes
avg_outcome_annotated <- left_join(avg_outcome, baseline_means, by = "trial")

# Plot
ggplot(te_df, aes(x = baseline, y = treatment_effect, color = trial)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  geom_line(linewidth = 1.2) +
  geom_point(data = avg_outcome_annotated,
             aes(x = mean_baseline, y = treatment_effect, color = trial),
             size = 3, alpha = 0.7) +
  geom_rug(data = df, aes(x = baseline), inherit.aes = FALSE, sides = "b", alpha = 0.3) +
  coord_cartesian(xlim = range(df$baseline)) +
  labs(
    x = "Baseline Severity",
    y = "Treatment Effect (Active vs Control)"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    legend.title = element_blank()
  )
```

### Distentangling within- and across-study interaction

In this approach, we decompose the covariate `baseline` into two components: a within-trial centered value (`cbase`) and a trial-level mean (`xk_mean`). Specifically, we define `cbase = baseline - xk_mean` and include both `trt:cbase` and `xk_mean:trt` in the model. The coefficient for `trt:cbase` captures the within-trial treatment–covariate interaction, while the coefficient for `xk_mean:trt` represents the between-trial effect of the trial-level covariate mean on treatment effect.

By explicitly modeling both components, this formulation separates within- and between-trial sources of interaction. As a result, the estimate of the within-trial interaction is not biased by between-trial heterogeneity in the covariate distribution (as is the case in @sec-commonInteraction). This is especially important in avoiding aggregation bias when interpreting effect modification.

```{r}
#| message: FALSE
#| warning: FALSE
fit_hte_3 <- lmer(outcome ~ -1 + trial + trt + trial:baseline + 
                    trt:cbase + xk_mean:trt +
                    (0 + trt | trial) + (0 + trt:cbase | trial),
                  data = df)
```

The fitted model is:
```{r}
#| echo: false
fit_hte_3 
```

Since the between-trial variance in the treatment effects and interaction effects is close to zero, we may simplify the model by removing the random components:

```{r}
#| message: FALSE
#| warning: FALSE
fit_hte_3b <- glm(outcome ~ -1 + trial + trt + trial:baseline + 
                    trt:cbase + trt:xk_mean, data = df)
```

The model includes two interaction terms: `cbase:trt`, which captures the within-trial interaction between the centered covariate and treatment; and `xk_mean:trt`, which captures the across-trial interaction effect due to variation in trial-level covariate means. Together, these coefficients define a linear relationship between baseline severity and the estimated treatment effect (active vs control), while distinguishing within- and between-trial sources of effect modification. In @fig-hte-centering, we visualize this relationship using both model-predicted curves and trial-level marginal treatment effect estimates.

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Estimated treatment effect (active vs control) as a function of baseline severity for each trial. The red dashed line at 0 indicates no treatment benefit. Negative values suggest a favorable effect of the active treatment, while positive values suggest harm. Rug marks show the distribution of baseline values. Coloured lines and dots represent, respectively, the model-based treatment-effect curves and the marginal (average) treatment effect within each trial."
#| label: fig-hte-centering
#| fig-width: 8
#| fig-height: 5

# Extract trial-level covariate means (xk_mean assumed present in df)
trial_means <- df %>% distinct(trial, xk_mean)

# Compute slope and intercepts from model
beta_within <- coef(fit_hte_3b)["trt:cbase"]
beta_across <- coef(fit_hte_3b)["trt:xk_mean"]
beta_main <- coef(fit_hte_3b)["trt"]

# Trial-specific intercept = main trt effect + xk_mean[i] * beta_across
beta_intercepts <- trial_means %>%
  mutate(treatment_intercept = beta_main + xk_mean * beta_across)

# Treatment effect curves: trial-specific intercept + common within-trial slope
baseline_vals <- seq(min(df$baseline), max(df$baseline), length.out = 100)

# Build data for treatment effect curves
te_df <- expand.grid(
  baseline = baseline_vals,
  trial = unique(df$trial)
) %>%
  left_join(trial_means, by = "trial") %>%
  mutate(
    cbase = baseline - xk_mean,
    treatment_intercept = beta_main + xk_mean * beta_across,
    treatment_effect = treatment_intercept + beta_within * cbase
  ) %>%
  drop_na(treatment_effect)


# Compute marginal treatment effect per trial
grid_df <- df %>%
  select(trial, baseline, xk_mean) %>%
  expand_grid(trt = c(0, 1)) %>%
  mutate(cbase = baseline - xk_mean)

grid_df$pred <- predict(fit_hte_3b, newdata = grid_df)

avg_outcome <- grid_df %>%
  group_by(trial, trt) %>%
  summarise(mean_pred = mean(pred), .groups = "drop") %>%
  pivot_wider(names_from = trt, values_from = mean_pred, names_prefix = "trt_") %>%
  mutate(treatment_effect = trt_1 - trt_0)

# Mean baseline per trial
baseline_means <- df %>%
  group_by(trial) %>%
  summarise(mean_baseline = mean(baseline), .groups = "drop")

avg_outcome_annotated <- left_join(avg_outcome, baseline_means, by = "trial")

# Plot
ggplot(te_df, aes(x = baseline, y = treatment_effect, color = trial)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  geom_line(linewidth = 1.2) +
  geom_point(data = avg_outcome_annotated,
             aes(x = mean_baseline, y = treatment_effect, color = trial),
             size = 3, alpha = 0.7) +
  geom_rug(data = df, aes(x = baseline), inherit.aes = FALSE, sides = "b", alpha = 0.3) +
  coord_cartesian(xlim = range(df$baseline)) +
  labs(
    x = "Baseline Severity",
    y = "Treatment Effect (Active vs Control)"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    legend.title = element_blank()
  )

```
